{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YASgcDCc16vb"
      },
      "source": [
        "# AIPI 590 - XAI | Assignment #05\n",
        "### GradCAM & Computer Vision\n",
        "### Peter Banyas\n",
        "\n",
        "#### Include the button below. Change the link to the location in your github repository:\n",
        "#### Example: https://colab.research.google.com/github/banyasp/aipi590_hw5_gradCAM/blob/main/hw5.ipynb\n",
        "\n",
        "\n",
        "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/banyasp/aipi590_hw5_gradCAM/blob/main/hw5.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setup**"
      ],
      "metadata": {
        "id": "j5DJrJoG3uPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grad-cam pillow torch torchvision"
      ],
      "metadata": {
        "id": "5c6dT6mY4NXY",
        "outputId": "39b70d93-29d1-4eb2-fbb4-61b7f50bce86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting grad-cam\n",
            "  Downloading grad-cam-1.5.5.tar.gz (7.8 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/7.8 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m131.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from grad-cam) (2.0.2)\n",
            "Collecting ttach (from grad-cam)\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from grad-cam) (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from grad-cam) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from grad-cam) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from grad-cam) (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.17.0)\n",
            "Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Building wheels for collected packages: grad-cam\n",
            "  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grad-cam: filename=grad_cam-1.5.5-py3-none-any.whl size=44284 sha256=e9ad805f4a99a50342162899e719822abb19dc6a4af789b48ecac13710c7a0c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/3b/09/2afc520f3d69bc26ae6bd87416759c820a3f7d05c1a077bbf6\n",
            "Successfully built grad-cam\n",
            "Installing collected packages: ttach, grad-cam\n",
            "Successfully installed grad-cam-1.5.5 ttach-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W_ZCAy1S16vc",
        "outputId": "fb779a0b-f0f4-4e2f-a42f-11f47cab74ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Duke-AI-XAI'...\n",
            "remote: Enumerating objects: 94, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 94 (delta 34), reused 63 (delta 15), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (94/94), 7.12 MiB | 11.48 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n",
            "/content/Duke-AI-XAI/templates\n",
            "template.ipynb\n"
          ]
        }
      ],
      "source": [
        "# Please use this to connect your GitHub repository to your Google Colab notebook\n",
        "# Connects to any needed files from GitHub and Google Drive\n",
        "import os\n",
        "\n",
        "# Remove Colab default sample_data\n",
        "!rm -r ./sample_data\n",
        "\n",
        "# Clone GitHub files to colab workspace\n",
        "repo_name = \"Duke-AI-XAI\" # Change to your repo name\n",
        "git_path = 'https://github.com/AIPI-590-XAI/Duke-AI-XAI.git' #Change to your path\n",
        "!git clone \"{git_path}\"\n",
        "\n",
        "# Install dependencies from requirements.txt file\n",
        "#!pip install -r \"{os.path.join(repo_name,'requirements.txt')}\" #Add if using requirements.txt\n",
        "\n",
        "# Change working directory to location of notebook\n",
        "notebook_dir = 'templates'\n",
        "path_to_notebook = os.path.join(repo_name,notebook_dir)\n",
        "%cd \"{path_to_notebook}\"\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "\n",
        "from pytorch_grad_cam import GradCAM, GradCAMPlusPlus, ScoreCAM, EigenCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import ssl\n",
        "import certifi\n",
        "import os\n",
        "from multiprocessing import Pool, cpu_count\n",
        "import time\n",
        "\n",
        "# Fix SSL certificate verification issue\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs('output', exist_ok=True)"
      ],
      "metadata": {
        "id": "NF5OMT0n3kb_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CAM processing**"
      ],
      "metadata": {
        "id": "lHW0mBns3x0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# originally built with claude sonnet 4.5, Oct 6 @ 8:40am. iteratively improved with cursor (claude 4.5 sonnet-powered). see ./cursor_logs for details.\n",
        "# Optimized for faster ScoreCAM processing with parallel image processing\n",
        "\n",
        "def process_single_image(img_info):\n",
        "    \"\"\"\n",
        "    Worker function to process a single image with all CAM methods.\n",
        "    This function will be called in parallel for each image.\n",
        "    \"\"\"\n",
        "    img_idx, total_imgs, emotion_folder, img_name = img_info\n",
        "\n",
        "    # Each worker initializes its own model and CAM instances\n",
        "    # Note: For GPU, this will use the same GPU but different CUDA contexts\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load model for this worker\n",
        "    model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Target layer (last conv layer in ResNet50)\n",
        "    target_layers = [model.layer4[-1]]\n",
        "\n",
        "    # Initialize CAM methods for this worker\n",
        "    cam_algorithms = {\n",
        "        'GradCAM': GradCAM(model=model, target_layers=target_layers),\n",
        "        'GradCAM++': GradCAMPlusPlus(model=model, target_layers=target_layers),\n",
        "        'EigenCAM': EigenCAM(model=model, target_layers=target_layers),\n",
        "        'Score-CAM': ScoreCAM(model=model, target_layers=target_layers)\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Processing image {img_idx}/{total_imgs}: {img_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Load and preprocess image\n",
        "    img = Image.open(f'emotion_dataset/{emotion_folder}/{img_name}.jpg').convert('RGB')\n",
        "    img_resized = img.resize((224, 224))\n",
        "    img_array = np.array(img_resized) / 255.0\n",
        "    img_tensor = transforms.ToTensor()(img_resized).unsqueeze(0).to(device)\n",
        "\n",
        "    # Generate visualizations for all methods\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
        "\n",
        "    # Original image\n",
        "    axes[0].imshow(img_resized)\n",
        "    axes[0].set_title('Original Image')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Generate CAM for each method\n",
        "    for idx, (name, cam) in enumerate(cam_algorithms.items(), 1):\n",
        "        print(f\"  [{img_name}] Generating {name}...\")\n",
        "        grayscale_cam = cam(input_tensor=img_tensor, targets=None)\n",
        "        visualization = show_cam_on_image(img_array, grayscale_cam[0], use_rgb=True)\n",
        "\n",
        "        axes[idx].imshow(visualization)\n",
        "        axes[idx].set_title(name)\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "        # Save individual visualizations\n",
        "        output_img = Image.fromarray(visualization)\n",
        "        output_img.save(f'output/{name.lower().replace(\"-\", \"\")}_output_{img_name}.jpg')\n",
        "        print(f\"    [{img_name}] Saved output/{name.lower().replace('-', '')}_output_{img_name}.jpg\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    comparison_path = f'output/cam_comparison_{img_name}.png'\n",
        "    plt.savefig(comparison_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"  [{img_name}] Comparison saved as '{comparison_path}'\")\n",
        "    plt.close()\n",
        "\n",
        "    # Print predicted class\n",
        "    with torch.no_grad():\n",
        "        output = model(img_tensor)\n",
        "        pred_class = output.argmax(dim=1).item()\n",
        "        confidence = torch.softmax(output, dim=1)[0][pred_class].item()\n",
        "        print(f\"  [{img_name}] Predicted class index: {pred_class}\")\n",
        "        print(f\"  [{img_name}] Confidence: {confidence:.2%}\")\n",
        "\n",
        "    # Clean up\n",
        "    del model, cam_algorithms\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "    return img_name"
      ],
      "metadata": {
        "id": "9ktdr2ay3iQg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  # List of images to process - add your image paths here\n",
        "  # Format: (emotion_folder, image_name)\n",
        "  img_list = [\n",
        "      ('happy', 'happy_01932'),\n",
        "      ('happy', 'happy_01419'),\n",
        "      ('disgust', 'disgust_00024'),\n",
        "      ('disgust', 'disgust_00045'),\n",
        "      ('angry', 'angry_00009'),\n",
        "      ('angry', 'angry_00021'),\n",
        "      ('surprise', 'surprise_00007'),\n",
        "      ('surprise', 'surprise_00019'),\n",
        "      ('sad', 'sad_00007'),\n",
        "      ('sad', 'sad_00018'),\n",
        "      ('neutral', 'neutral_00017'),\n",
        "      ('neutral', 'neutral_00025')\n",
        "  ]\n",
        "\n",
        "  # Configure number of parallel workers\n",
        "  # For CPU: use cpu_count() or cpu_count() - 1\n",
        "  # For GPU: use 2-4 to avoid GPU memory issues (GPU context switching has overhead)\n",
        "  num_workers = cpu_count() - 1\n",
        "  # min(4, len(img_list))  # Use up to 4 workers, but no more than number of images\n",
        "\n",
        "  print(f\"\\n{'='*60}\")\n",
        "  print(f\"Starting parallel processing with {num_workers} workers\")\n",
        "  print(f\"Total images to process: {len(img_list)}\")\n",
        "  print(f\"{'='*60}\\n\")\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  # Prepare arguments for each worker (add index and total count)\n",
        "  img_info_list = [\n",
        "      (idx, len(img_list), emotion_folder, img_name)\n",
        "      for idx, (emotion_folder, img_name) in enumerate(img_list, 1)\n",
        "  ]\n",
        "\n",
        "  # Process images in parallel using multiprocessing\n",
        "  with Pool(processes=num_workers) as pool:\n",
        "      results = pool.map(process_single_image, img_info_list)\n",
        "\n",
        "  elapsed_time = time.time() - start_time\n",
        "\n",
        "  print(f\"\\n{'='*60}\")\n",
        "  print(f\"All {len(img_list)} images processed successfully!\")\n",
        "  print(f\"Total time: {elapsed_time:.2f} seconds\")\n",
        "  print(f\"Average time per image: {elapsed_time/len(img_list):.2f} seconds\")\n",
        "  print(f\"{'='*60}\")"
      ],
      "metadata": {
        "id": "i-7fGSVR2WvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-Wujh9yJ4ah_",
        "outputId": "8856b7a3-fc95-428a-d098-28c8c0854eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}