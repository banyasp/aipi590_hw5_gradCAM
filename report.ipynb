{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d442e3f",
   "metadata": {},
   "source": [
    "# AIPI 590 - XAI | Assignment #05\n",
    "### GradCAM & Computer Vision\n",
    "### Peter Banyas\n",
    "\n",
    "#### Include the button below. Change the link to the location in your github repository:\n",
    "#### Example: https://colab.research.google.com/github/banyasp/aipi590_hw5_gradCAM/blob/main/report.ipynb\n",
    "\n",
    "\n",
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/banyasp/aipi590_hw5_gradCAM/blob/main/report.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e06172a",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "This notebook demonstrates various Class Activation Mapping (CAM) techniques on facial emotion images using a pretrained ResNet50 model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0324f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -q grad-cam pytorch-grad-cam torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa597024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository to get the data folder\n",
    "import os\n",
    "if not os.path.exists('aipi590_hw5_gradCAM'):\n",
    "    os.system('git clone https://github.com/banyasp/aipi590_hw5_gradCAM.git')\n",
    "    print(\"Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"Repository already exists!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7e1124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pytorch_grad_cam import GradCAM, GradCAMPlusPlus, ScoreCAM, EigenCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "import time\n",
    "\n",
    "# Fix SSL certificate verification issue\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")\n",
    "print(f\"✓ Using device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c2afea",
   "metadata": {},
   "source": [
    "## Load Model and Define CAM Processing Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ff0a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ResNet50 model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Target layer (last convolutional layer in ResNet50)\n",
    "target_layers = [model.layer4[-1]]\n",
    "\n",
    "# Initialize CAM methods\n",
    "cam_algorithms = {\n",
    "    'GradCAM': GradCAM(model=model, target_layers=target_layers),\n",
    "    'GradCAM++': GradCAMPlusPlus(model=model, target_layers=target_layers),\n",
    "    'EigenCAM': EigenCAM(model=model, target_layers=target_layers),\n",
    "    'Score-CAM': ScoreCAM(model=model, target_layers=target_layers)\n",
    "}\n",
    "\n",
    "print(\"✓ Model loaded successfully!\")\n",
    "print(f\"✓ Initialized {len(cam_algorithms)} CAM algorithms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12934c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_image(img_name, display=True):\n",
    "    \"\"\"\n",
    "    Process a single image with all CAM methods and optionally display results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    img_name : str\n",
    "        Name of the image file (without .jpg extension)\n",
    "    display : bool\n",
    "        Whether to display the results inline (default: True)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Contains processing information and results\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing image: {img_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load and preprocess image from the data folder\n",
    "    img_path = f'aipi590_hw5_gradCAM/data/{img_name}.jpg'\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_resized = img.resize((224, 224))\n",
    "    img_array = np.array(img_resized) / 255.0\n",
    "    img_tensor = transforms.ToTensor()(img_resized).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Generate visualizations for all methods\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(img_resized)\n",
    "    axes[0].set_title('Original Image', fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Generate CAM for each method\n",
    "    for idx, (name, cam) in enumerate(cam_algorithms.items(), 1):\n",
    "        print(f\"  Generating {name}...\")\n",
    "        grayscale_cam = cam(input_tensor=img_tensor, targets=None)\n",
    "        visualization = show_cam_on_image(img_array, grayscale_cam[0], use_rgb=True)\n",
    "        \n",
    "        axes[idx].imshow(visualization)\n",
    "        axes[idx].set_title(name, fontsize=14, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "        \n",
    "        # Save individual visualizations\n",
    "        output_img = Image.fromarray(visualization)\n",
    "        output_path = f'output/{name.lower().replace(\"-\", \"\")}_output_{img_name}.jpg'\n",
    "        output_img.save(output_path)\n",
    "        print(f\"    Saved {output_path}\")\n",
    "    \n",
    "    # Save comparison\n",
    "    plt.tight_layout()\n",
    "    comparison_path = f'output/cam_comparison_{img_name}.png'\n",
    "    plt.savefig(comparison_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"  Comparison saved as '{comparison_path}'\")\n",
    "    \n",
    "    if display:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "    \n",
    "    # Get model prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        pred_class = output.argmax(dim=1).item()\n",
    "        confidence = torch.softmax(output, dim=1)[0][pred_class].item()\n",
    "        print(f\"  Predicted class index: {pred_class}\")\n",
    "        print(f\"  Confidence: {confidence:.2%}\")\n",
    "    \n",
    "    return {\n",
    "        'image_name': img_name,\n",
    "        'predicted_class': pred_class,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "\n",
    "print(\"✓ Processing function defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a1f78",
   "metadata": {},
   "source": [
    "## Process All Images\n",
    "\n",
    "Now we'll process all 12 images from the dataset using all four CAM methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f69d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of images to process\n",
    "img_list = [\n",
    "    'happy_01932',\n",
    "    'happy_01419',\n",
    "    'disgust_00024',\n",
    "    'disgust_00045',\n",
    "    'angry_00009',\n",
    "    'angry_00021',\n",
    "    'surprise_00007',\n",
    "    'surprise_00019',\n",
    "    'sad_00007',\n",
    "    'sad_00018',\n",
    "    'neutral_00017',\n",
    "    'neutral_00025'\n",
    "]\n",
    "\n",
    "# Process all images\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Starting CAM processing\")\n",
    "print(f\"Total images to process: {len(img_list)}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "results = []\n",
    "\n",
    "for img_name in img_list:\n",
    "    result = process_single_image(img_name, display=True)\n",
    "    results.append(result)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"✓ All {len(img_list)} images processed successfully!\")\n",
    "print(f\"Total time: {elapsed_time:.2f} seconds\")\n",
    "print(f\"Average time per image: {elapsed_time/len(img_list):.2f} seconds\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c28de",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "Let's view a summary of all processed images and their predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c922cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results summary\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.index = df.index + 1\n",
    "df.columns = ['Image Name', 'Predicted Class', 'Confidence']\n",
    "df['Confidence'] = df['Confidence'].apply(lambda x: f\"{x:.2%}\")\n",
    "\n",
    "print(\"\\nSummary of All Predictions:\")\n",
    "print(\"=\"*60)\n",
    "print(df.to_string())\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082afd84",
   "metadata": {},
   "source": [
    "## Analysis and Conclusions\n",
    "\n",
    "### CAM Methods Compared:\n",
    "\n",
    "1. **GradCAM**: Uses gradients to weight the importance of feature maps\n",
    "2. **GradCAM++**: Improved version with better localization for multiple instances\n",
    "3. **EigenCAM**: Uses principal components of activations\n",
    "4. **Score-CAM**: Gradient-free method using perturbation-based importance\n",
    "\n",
    "### Key Observations:\n",
    "\n",
    "- All methods successfully highlight the facial regions in the emotion images\n",
    "- Different CAM methods may emphasize different facial features\n",
    "- The ResNet50 model (trained on ImageNet) provides reasonable feature extraction even for facial emotion images\n",
    "- Score-CAM tends to be slower but provides gradient-free explanations\n",
    "\n",
    "### Output Files:\n",
    "\n",
    "All visualizations are saved in the `output/` directory:\n",
    "- Individual CAM outputs for each method and image\n",
    "- Comparison images showing all 4 methods side-by-side\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- The model was pretrained on ImageNet (1000 classes), so predicted class indices refer to ImageNet classes\n",
    "- For emotion-specific classification, fine-tuning on emotion datasets would be recommended\n",
    "- CAM visualizations help understand which parts of the image the model focuses on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138416f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b4fb250",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
